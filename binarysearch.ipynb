{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7600714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Search Time Complexity Analyzer\n",
    "# Simple version for Jupyter Notebook / GitHub\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random\n",
    "\n",
    "def binary_search(arr, target):\n",
    "    \"\"\"Binary search with step counting\"\"\"\n",
    "    left, right = 0, len(arr) - 1\n",
    "    steps = 0\n",
    "    \n",
    "    while left <= right:\n",
    "        steps += 1\n",
    "        mid = (left + right) // 2\n",
    "        \n",
    "        if arr[mid] == target:\n",
    "            return mid, steps\n",
    "        elif arr[mid] < target:\n",
    "            left = mid + 1\n",
    "        else:\n",
    "            right = mid - 1\n",
    "    \n",
    "    return -1, steps\n",
    "\n",
    "def measure_performance(sizes):\n",
    "    \"\"\"Measure binary search performance across different array sizes\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    print(\"Testing Binary Search Performance...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for size in sizes:\n",
    "        # Generate sorted array\n",
    "        arr = sorted(random.sample(range(1, size * 3), size))\n",
    "        target = arr[size // 2]  # Pick middle element to ensure it's found\n",
    "        \n",
    "        # Measure execution time (multiple trials for accuracy)\n",
    "        times = []\n",
    "        steps_list = []\n",
    "        \n",
    "        for _ in range(50):  # 50 trials\n",
    "            start_time = time.perf_counter()\n",
    "            pos, steps = binary_search(arr, target)\n",
    "            end_time = time.perf_counter()\n",
    "            \n",
    "            times.append((end_time - start_time) * 1_000_000)  # Convert to microseconds\n",
    "            steps_list.append(steps)\n",
    "        \n",
    "        avg_time = np.mean(times)\n",
    "        avg_steps = np.mean(steps_list)\n",
    "        theoretical_max = int(np.ceil(np.log2(size)))\n",
    "        \n",
    "        results.append({\n",
    "            'size': size,\n",
    "            'time': avg_time,\n",
    "            'steps': avg_steps,\n",
    "            'max_steps': theoretical_max\n",
    "        })\n",
    "        \n",
    "        print(f\"Size: {size:6,} | Time: {avg_time:6.2f}Î¼s | Steps: {avg_steps:4.1f} | Max: {theoretical_max:2d}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def plot_results(results):\n",
    "    \"\"\"Plot the performance results\"\"\"\n",
    "    sizes = [r['size'] for r in results]\n",
    "    times = [r['time'] for r in results]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(sizes, times, color='#2E86AB', s=100, alpha=0.8, edgecolors='white', linewidth=2)\n",
    "    plt.plot(sizes, times, color='#A23B72', linestyle='--', alpha=0.7, linewidth=2)\n",
    "    \n",
    "    plt.xlabel('Array Size (n)', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('Execution Time (microseconds)', fontsize=12, fontweight='bold')\n",
    "    plt.title('Binary Search: Time Complexity Analysis\\nO(log n) Performance', fontsize=14, fontweight='bold')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add some annotations\n",
    "    if len(sizes) > 1:\n",
    "        improvement = sizes[-1] / sizes[0]  # How many times larger\n",
    "        time_increase = times[-1] / times[0]  # How many times slower\n",
    "        \n",
    "        plt.text(0.05, 0.95, f'Array size increased {improvement:.0f}x\\nTime increased only {time_increase:.1f}x', \n",
    "                transform=plt.gca().transAxes, verticalalignment='top',\n",
    "                bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.8),\n",
    "                fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Test with different array sizes\n",
    "    test_sizes = [100, 500, 1000, 5000, 10000, 50000, 100000]\n",
    "    \n",
    "    print(\"ðŸ” Binary Search Time Complexity Analyzer\")\n",
    "    print(\"This demonstrates O(log n) performance scaling\\n\")\n",
    "    \n",
    "    # Run the performance test\n",
    "    results = measure_performance(test_sizes)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"ANALYSIS COMPLETE!\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Show the scaling efficiency\n",
    "    if len(results) > 1:\n",
    "        first_size, first_time = results[0]['size'], results[0]['time']\n",
    "        last_size, last_time = results[-1]['size'], results[-1]['time']\n",
    "        \n",
    "        size_ratio = last_size / first_size\n",
    "        time_ratio = last_time / first_time\n",
    "        \n",
    "        print(f\"\\nðŸ“Š EFFICIENCY DEMONSTRATION:\")\n",
    "        print(f\"   Array size increased: {size_ratio:.0f}x ({first_size:,} â†’ {last_size:,})\")\n",
    "        print(f\"   Time increased only: {time_ratio:.1f}x ({first_time:.2f}Î¼s â†’ {last_time:.2f}Î¼s)\")\n",
    "        print(f\"   This proves O(log n) efficiency! ðŸŽ¯\")\n",
    "    \n",
    "    # Plot the results\n",
    "    print(f\"\\nðŸ“ˆ Generating performance graph...\")\n",
    "    plot_results(results)\n",
    "    \n",
    "    # Additional analysis\n",
    "    print(f\"\\nðŸ§® THEORETICAL vs ACTUAL:\")\n",
    "    print(\"-\" * 40)\n",
    "    for r in results:\n",
    "        efficiency = (r['steps'] / r['max_steps']) * 100\n",
    "        print(f\"Size {r['size']:6,}: {r['steps']:4.1f} steps (vs max {r['max_steps']:2d}) = {efficiency:5.1f}% of maximum\")\n",
    "\n",
    "# Interactive function for custom testing\n",
    "def test_custom_size(size, target=None):\n",
    "    \"\"\"Test binary search with a custom array size\"\"\"\n",
    "    if size <= 0 or size > 1000000:\n",
    "        print(\"Please enter a size between 1 and 1,000,000\")\n",
    "        return\n",
    "    \n",
    "    # Generate array\n",
    "    arr = sorted(random.sample(range(1, size * 3), size))\n",
    "    \n",
    "    if target is None:\n",
    "        target = arr[size // 2]  # Pick middle element\n",
    "    \n",
    "    print(f\"\\nðŸŽ¯ Testing with array size: {size:,}\")\n",
    "    print(f\"   Target: {target}\")\n",
    "    print(f\"   Array range: {arr[0]} to {arr[-1]}\")\n",
    "    \n",
    "    # Measure performance\n",
    "    start_time = time.perf_counter()\n",
    "    position, steps = binary_search(arr, target)\n",
    "    end_time = time.perf_counter()\n",
    "    \n",
    "    execution_time = (end_time - start_time) * 1_000_000\n",
    "    theoretical_max = int(np.ceil(np.log2(size)))\n",
    "    \n",
    "    print(f\"\\nðŸ“‹ RESULTS:\")\n",
    "    print(f\"   Found at position: {position}\")\n",
    "    print(f\"   Steps taken: {steps}\")\n",
    "    print(f\"   Execution time: {execution_time:.3f} microseconds\")\n",
    "    print(f\"   Theoretical max steps: {theoretical_max}\")\n",
    "    print(f\"   Efficiency: {(steps/theoretical_max)*100:.1f}% of maximum\")\n",
    "\n",
    "# Example usage for interactive testing:\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸš€ INTERACTIVE TESTING\")\n",
    "print(\"=\"*60)\n",
    "print(\"You can test custom sizes using:\")\n",
    "print(\"test_custom_size(1000)      # Test with 1000 elements\")\n",
    "print(\"test_custom_size(50000, 123) # Test with 50000 elements, target=123\")\n",
    "print(\"\\nTry it out! ðŸ‘†\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
